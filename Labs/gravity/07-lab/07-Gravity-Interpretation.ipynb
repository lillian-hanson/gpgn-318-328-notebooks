{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014fc98a-19dd-4083-8697-29914625d11a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Gravity Model fitting\n",
    "------\n",
    "* Due date: October 15, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15d442-c967-4d0c-82d7-a70472ddb268",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "Our objectives are:\n",
    "* Familiarize with, and practice, the interpretation of gravity data by a trial-and-error method of modeling.\n",
    "* Understand the ambiguity between the recovered density, geometry, and depth of a causative body during gravity interpretation when the data contain varying error levels.\n",
    "* Quantitatively interpret the gravity data you collected in the previous lab over the “possible” steam tunnel beneath the CSM campus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc774289-d6ee-497d-813c-d1bf4d6cd367",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grav_utils.grav_interact'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgrav_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgrav_interact\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GravInteract\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'grav_utils.grav_interact'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from grav_utils.grav_interact import GravInteract\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc9a90-3e0c-4eb5-af04-78f4e94fc707",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Background\n",
    "### Interactive Widget\n",
    "\n",
    "The gravity modelling widget you used to forward model, can also load in observed data, additionally with its standard deviation, to compare against!\n",
    "\n",
    "The controls are all the same, except that now your observation locations should be the same as your observed data locations, and you can additionally pass a data and standard deviation arrays.\n",
    "\n",
    "You should also notice that when data are loaded into it, it displays a value called \"misfit\" representing how poorly the observed and predicted data match each other (the smaller the the closer it matches the observed data). In this widget, the misfit is defined as:\n",
    "\n",
    "$$ \\frac{1}{N_d}\\sum_{i=1}^{N_d} \\left(\\frac{d_{pre,i} - d_{obs,i}}{\\sigma_i}\\right)^2$$\n",
    "\n",
    "**New**: You can also easily get and set the value of the denisty programatically with\n",
    "* `modeler.get_density()`\n",
    "* `modeler.set_density(value)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f5037-b591-49ca-8941-c52735de1e4d",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082781be-589d-4d7c-982b-93dfa2fa3aba",
   "metadata": {},
   "source": [
    "You will be interpreting three sets of data in this lab. The first two are supplied in the data files:\n",
    "`data\\obs1.grv` and `data\\obs2.grv`. For the third data set, use the data you collected over the steam tunnel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9d202-3bcb-4588-9c3b-612beecd3569",
   "metadata": {},
   "source": [
    "## Data Set 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca1aad-51b7-4554-9c71-2d0dff4c74d4",
   "metadata": {},
   "source": [
    "For the first part we will load in the `data/obs1.grv` csv data file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a3ad37-5549-4242-b16e-120791f408f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dat1_frame = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m07-lab/data/obs1.grv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m dat1_frame\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dat1_frame = pd.read_csv('07-lab/data/obs1.grv')\n",
    "dat1_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9fd58-9636-4598-8f9c-85902c681795",
   "metadata": {},
   "source": [
    "Then to make it a little clearer for the inputs to the modeler, let's collect the values of interest into there own variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2847da93-8f37-4369-abe4-ac62d625a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = np.c_[dat1_frame['Profile (m)'], dat1_frame['height (m)']]\n",
    "dat1 = dat1_frame['G_D (mGal)']\n",
    "std1 = dat1_frame['STD (mGal)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46640a-2afa-4fd2-a777-37f5e8b32e35",
   "metadata": {},
   "source": [
    "And finally pass it to the modeler.\n",
    "\n",
    "\n",
    "### Question 1: \n",
    "Based on the responses you saw in previous labs, what do you think the model is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7b5e3a-63c2-482d-8e7d-488364f76909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GravInteract' object has no attribute 'set_density'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m modeler = GravInteract(obs1, dat1, std1)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodeler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_density\u001b[49m(\u001b[32m1.4\u001b[39m)\n\u001b[32m      3\u001b[39m modeler.set_polygons([[[-\u001b[32m256.84434572207124\u001b[39m, -\u001b[32m125.76539261087817\u001b[39m], [-\u001b[32m61.90051105849918\u001b[39m, -\u001b[32m132.66794099839865\u001b[39m], [-\u001b[32m97.18910794264292\u001b[39m, -\u001b[32m311.0828392257332\u001b[39m], [-\u001b[32m151.0761380890583\u001b[39m, -\u001b[32m625.7769278553957\u001b[39m], [-\u001b[32m4.8113419773583965\u001b[39m, -\u001b[32m825.3390328400601\u001b[39m], [-\u001b[32m551.3797906052896\u001b[39m, -\u001b[32m671.829721313395\u001b[39m], [-\u001b[32m297.34093420075817\u001b[39m, -\u001b[32m479.9430819050642\u001b[39m], [-\u001b[32m235.7557568905689\u001b[39m, -\u001b[32m364.8110982600657\u001b[39m]]])\n\u001b[32m      4\u001b[39m modeler\n",
      "\u001b[31mAttributeError\u001b[39m: 'GravInteract' object has no attribute 'set_density'"
     ]
    }
   ],
   "source": [
    "modeler = GravInteract(obs1, dat1, std1)\n",
    "modeler.set_density(1.4)\n",
    "modeler.set_polygons([[[-256.84434572207124, -125.76539261087817], [-61.90051105849918, -132.66794099839865], [-97.18910794264292, -311.0828392257332], [-151.0761380890583, -625.7769278553957], [-4.8113419773583965, -825.3390328400601], [-551.3797906052896, -671.829721313395], [-297.34093420075817, -479.9430819050642], [-235.7557568905689, -364.8110982600657]]])\n",
    "modeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8f4ef-53a6-4b30-baa0-7e94c8cab234",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Now begin the process of trial-and-error modeling to interpret the data set and find three different polygons that each fit the data to within their standard deviations/ Remember to save the polygon models so you can reload them later, either with the `modeler.get_polygons()` and `modeler.load_polygons()` methods, or the save and load buttons on the widget. You can also get and set the density with `modeler.set_density()` and `modeler.get_density()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572481d-ac1d-43ba-96be-8dc7c6c06d67",
   "metadata": {},
   "source": [
    "1) Find a dipping slab with four vertices and a density contrast of 1.0 g/cc\n",
    "\n",
    "[array([[-300.27222688, -177.66293216],\n",
    "        [ 154.43640062, -159.76517311],\n",
    "        [-240.44214431, -696.69794465],\n",
    "        [-509.67751586, -428.23155888]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08f37a-d0a5-412d-a27e-8760b1fbdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler.get_polygons()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de91638-93f5-4b9f-9d63-a5b715a4bfd3",
   "metadata": {},
   "source": [
    "2) Find a similar body with a density contrast of 0.6 g/cc, with a few more vertices (Likely starting from your model in part 1)\n",
    " [array([[ -470.82417211,  -195.83378986],\n",
    "        [ -108.78562202,   -70.8819954 ],\n",
    "        [   51.34681359,  -299.96028525],\n",
    "        [   37.42225398,  -681.75743501],\n",
    "        [  -80.93650278,  -772.00039768],\n",
    "        [   65.27137321, -1237.09874375],\n",
    "        [ -164.4838605 ,  -855.30159399],\n",
    "        [ -394.23909421,  -494.32974331]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b801939-0e35-492b-8280-fa130d61b4a7",
   "metadata": {},
   "source": [
    "3) Find a model that has a density of 1.4 g/cc and a flat top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7093f-f74a-4ec1-b0f2-a6855d735c6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**note**: For each of these cases, you should aim to get your data misfit close to 1.\n",
    "Also, it could be helpful to create a new widget for each part of this question (with different variable names so they don't clobber each other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cec1d4-f4af-4f24-bba6-de8c11888e4b",
   "metadata": {},
   "source": [
    "## Data Set 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb8332-a351-4cea-ba3f-9c810df1ae8b",
   "metadata": {},
   "source": [
    "For the second part we will load in the `data/obs2.grv` csv data file using pandas. You should notice that these data look similar to **Data Set 2**, but have a much lower standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a18679-c7d7-43c8-bc0e-33b41b0f70c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat2_frame = pd.read_csv('data/obs2.grv')\n",
    "obs2= np.c_[dat2_frame['Profile (m)'], dat2_frame['height (m)']]\n",
    "dat2 = dat2_frame['G_D (mGal)']\n",
    "std2 = dat2_frame['STD (mGal)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06bd0e-b216-4729-a5ff-b6c37ac31c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler_part2 = GravInteract(obs2, dat2, std2)\n",
    "modeler_part2.set_polygons([[[-256.84434572207124, -125.76539261087817], [-61.90051105849918, -132.66794099839865], [-97.18910794264292, -311.0828392257332], [-151.0761380890583, -625.7769278553957], [-4.8113419773583965, -825.3390328400601], [-551.3797906052896, -671.829721313395], [-297.34093420075817, -479.9430819050642], [-235.7557568905689, -364.8110982600657]]])\n",
    "modeler_part2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0ec78a-73cd-4308-a61f-fc3db4ffb6ba",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "1) Input the three models you found in the previous question (part 2), are they still acceptable models? Discuss why or why not.\n",
    "   - Q2-1: Misfit 8.640\n",
    "   - Q2-2: Misfit 95.164\n",
    "   - Q2-3: Misfit 54.719\n",
    "2) Pick one of the cases that is not acceptable, and find a new model that fits the data. Discuss the difference between the model derived for the `obs1.grv` data, and this model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922aa4e-3eb1-4251-9c5c-e4778dbab43b",
   "metadata": {},
   "source": [
    "## Tunnel data\n",
    "Now that you are hopefully comfortable with the process of trial-and-error modeling, lets attempt it with the data you collected over the tunnel.\n",
    "\n",
    "1) Read in the processed gravity data (drift, free-air, and simple Bouguer corrected).\n",
    "    * You will also need the *profile distance*, and height of each observation point.\n",
    "\n",
    "**Note** you should read in your own data, the 2024 data is provided as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bce6e-f52f-4bd9-9e5c-8da75e5e158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in code from lab 6\n",
    "\n",
    "column_names = [\n",
    "    \"LINE\",\"STATION\",\"ALT\",\"GRAV\",\"SD\",\"TILTX\",\"TILTY\",\"TEMP\",\"TIDE\",\n",
    "    \"DUR\",\"REJ\",\"TIME\",\"DEC_TIME_DATE\",\"TERRAIN\",\"DATE\"\n",
    "]\n",
    "\n",
    "dfcg5 = pd.read_csv('06-lab/data/grp2/CG5-2.TXT', sep=r'\\s+', skiprows=52, header=None, names=column_names)\n",
    "\n",
    "loc_data = pd.read_csv('06-lab/data/grp2/grp2-lab6.csv')\n",
    "locdf = loc_data\n",
    "\n",
    "loccols = ['STATION', 'Northing', 'Easting', 'ELEV', 'Notes']\n",
    "locdf.columns = loccols[:len(locdf.columns)]\n",
    "\n",
    "for col in ['Northing', 'Easting', 'ELEV']:\n",
    "    if col in locdf.columns:\n",
    "        locdf[col] = pd.to_numeric(locdf[col], errors = 'coerce')\n",
    "locdf = locdf.drop(index = 15)\n",
    "\n",
    "reorder = locdf.iloc[33:34]\n",
    "locdf = locdf.drop(index = 34)\n",
    "locdf_top = locdf.iloc[:24]\n",
    "locdf_bottom = locdf.iloc[24:]\n",
    "\n",
    "locdf = pd.concat([locdf_top, reorder, locdf_bottom]).reset_index(drop=True)\n",
    "\n",
    "# clean columns\n",
    "dfcg5['STATION'] = dfcg5['STATION'].astype(str).str.strip()\n",
    "locdf['STATION'] = locdf['STATION'].astype(str).str.strip()\n",
    "\n",
    "dfcg5['STATION_NUM'] = pd.to_numeric(dfcg5['STATION'], errors='coerce')\n",
    "locdf['STATION_NUM'] = pd.to_numeric(locdf['STATION'], errors='coerce')\n",
    "\n",
    "# merge data frames\n",
    "df = pd.merge(dfcg5, locdf[['STATION_NUM', 'Northing', 'Easting', 'ELEV']],\n",
    "              on='STATION_NUM', how='left')\n",
    "\n",
    "df = df[['STATION_NUM', 'GRAV', 'Northing', 'Easting', 'TIME', 'ELEV', 'SD']]\n",
    "df = df.sort_values('STATION_NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69b070-1bc9-4a51-b096-c4e52723d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat_tunnel_frame = df\n",
    "obs_tun_x = dat_tunnel_frame['STATION_NUM']\n",
    "obs_tun_z = dat_tunnel_frame['ELEV']\n",
    "\n",
    "# Note I'm subtracting the elevation at the base station here\n",
    "# So I'm not working with elevations on the order of 1741...\n",
    "obs_tunnel = np.c_[obs_tun_x, obs_tun_z-obs_tun_z[20]]\n",
    "gz_tunnel = dat_tunnel_frame['GRAV']\n",
    "std_tunnel = dat_tunnel_frame['SD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fdc1c-61ce-4432-8e13-a99faacd3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(obs_tunnel[:, 0], gz_tunnel)\n",
    "plt.errorbar(obs_tunnel[:, 0], gz_tunnel, std_tunnel, ls='')\n",
    "plt.title('Gz Observed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01709107-570d-4007-beb4-a282724a1a4b",
   "metadata": {},
   "source": [
    "2) You might have noticed in your previous lab that there was still a trend in your data set. We want to isolate the gravity anomaly due to the tunnels,\n",
    "    * Fit a line to your data set (`np.polynomial.Polynomial.fit()`) as a function of profile distance and processed gravity\n",
    "    * Remove that linear trend from your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd642b-0cf2-41e9-af77-2d22a37d0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.polynomial.Polynomial.fit(obs_tunnel[:, 0], gz_tunnel, deg=1)\n",
    "# Note you could also weight this by the STD... since we have it\n",
    "line_weighted = np.polynomial.Polynomial.fit(obs_tunnel[:, 0], gz_tunnel, deg=1, w=1/std_tunnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac463e65-1209-4315-be55-b5a3ff28ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gz_tun_detrend = gz_tunnel - line_weighted(obs_tunnel[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9253a68d-cf40-4bd2-95ce-bf2a6426c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(obs_tunnel[:, 0], gz_tun_detrend)\n",
    "plt.errorbar(obs_tunnel[:, 0], gz_tun_detrend, std_tunnel, ls='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a0986-db10-43ea-b79b-a2a1d52c51e9",
   "metadata": {},
   "source": [
    "Start up the widget with this data.\n",
    "\n",
    "3) Find a model that fits your data set, and is consistent with the prior information you have about the tunnel (think the measurements you took).\n",
    "    * You can adjust the position and density contrast of the tunnel to make it fit the data!\n",
    "    * Is there a range of density contrasts that could fit your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cc729-a858-4afc-ad03-12e04e5ae182",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler_tun = GravInteract(obs_tunnel, gz_tun_detrend, std_tunnel)\n",
    "# tunnel upper\n",
    "tunnel_u = np.array([\n",
    "    [-0.685, -0.30],\n",
    "    [0.685, -0.30], \n",
    "    [0.685, -2.26],\n",
    "    [-0.685, -2.26]\n",
    "])\n",
    "\n",
    "# tunnel upper\n",
    "tunnel_l = np.array([\n",
    "    [-0.683, -2.26], \n",
    "    [-2.207, -2.26],\n",
    "    [-2.207, -4.105],\n",
    "    [-0.683, -4.105]\n",
    "])\n",
    "\n",
    "modeler_tun.set_density(-1.62)\n",
    "modeler_tun.set_polygons([tunnel_l, tunnel_u])\n",
    "modeler_tun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3894e-2419-46f3-90a1-5eb4bb9b57eb",
   "metadata": {},
   "source": [
    "4) Discuss your ability to fit the data, and the quality of your recovered model in comparison to your previous knowledge of the tunnel(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd8ae9-1622-43ef-84ac-10c380c94e4d",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "Submit an informal report in pdf form detailing:\n",
    "1) Your name and lab title.\n",
    "1) Your three interpreted models using the `obs1.grv` data set, with a brief description of each. (Include an image of the data fit, the model, and list the locations of the polygon’s nodes).\n",
    "1) Plots showing how well your previous models fit the `obs2.grv` data, with a brief description of which models are still successful.\n",
    "1) The new model you found that better fits `obs2.grv`, and discuss the updates and show the updated data.\n",
    "1) Plots showing the model and data fit, as well as describe your chosen density contrast for the tunnel. Include the requested discussion from that section.\n",
    "1) Address the following discussion points:\n",
    "    1. How does the size of the model change as you decrease the assumed density contrast?\n",
    "    2. Based on Gauss’s law, can you predict how the product of the density contrast and the area of the polygon will change? Will it increase, remain the same, or decrease as you increase density contrast?\n",
    "    3. Can you uniquely determine the shapes of the sources that originally produced the data without knowledge of the density contrast? What if you do know the density contrast?\n",
    "7. How do the errors in the data affect your interpretation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be67687-002e-4363-8442-61be36dfbd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
